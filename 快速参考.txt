â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘           Lab-GPU å¿«é€Ÿå‚è€ƒå¡ (å·²å®‰è£…åˆ° graphAR ç¯å¢ƒ)          â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“Œ æ¿€æ´»ç¯å¢ƒ
  conda activate graphAR

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸš€ å¿«é€Ÿå¼€å§‹ï¼ˆä¸‰æ­¥ï¼‰
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1ï¸âƒ£  å¯åŠ¨æœåŠ¡
    lab-gpu server start --role master --host 127.0.0.1
    lab-gpu server add-node --name node-1 --gpus 2 --vram 24

2ï¸âƒ£  æäº¤ä»»åŠ¡
    lab-gpu submit --mem 10G "python train.py"
    æˆ–
    lab-gpu submit-batch --file tasks.json

3ï¸âƒ£  æ‰§è¡Œè°ƒåº¦
    lab-gpu server tick
    lab-gpu tui  (æ¨èä½¿ç”¨å¯è§†åŒ–ç•Œé¢)

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“‹ å¸¸ç”¨å‘½ä»¤
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

â–¸ æäº¤ä»»åŠ¡
  lab-gpu submit --mem 10G --priority normal "python train.py"
  lab-gpu submit --mem 16G --priority high --env graphAR "python exp.py"
  lab-gpu submit-batch --file tasks.json

â–¸ æŸ¥çœ‹çŠ¶æ€
  lab-gpu status              # ç®€è¦çŠ¶æ€
  lab-gpu status --json       # è¯¦ç»†çŠ¶æ€
  lab-gpu tui                 # å¯è§†åŒ–ç•Œé¢ â­

â–¸ æ—¥å¿—æŸ¥çœ‹
  lab-gpu logs 1              # æŸ¥çœ‹ä»»åŠ¡ 1
  lab-gpu logs 1 -f           # å®æ—¶è·Ÿè¸ª

â–¸ è°ƒåº¦æ§åˆ¶
  lab-gpu server tick         # è§¦å‘è°ƒåº¦
  lab-gpu server preempt --task-id 1  # æŠ¢å ä»»åŠ¡

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“ tasks.json æ ¼å¼
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

{
  "tasks": [
    {
      "cmd": "python train.py",     // å¿…å¡«ï¼šå‘½ä»¤
      "mem": "10G",                  // æ˜¾å­˜éœ€æ±‚
      "priority": "normal",          // high/normal/low
      "env": "graphAR",              // å¯é€‰ï¼šconda ç¯å¢ƒ
      "gpu_type": "RTX 3090",        // å¯é€‰ï¼šGPU å‹å·
      "time_limit": 3600             // å¯é€‰ï¼šæ—¶é—´é™åˆ¶ï¼ˆç§’ï¼‰
    }
  ]
}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ’¡ ä½¿ç”¨æŠ€å·§
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

âœ“ æäº¤å‰æµ‹è¯•    lab-gpu submit --mem 10G --dry-run "cmd"
âœ“ æ‰¹é‡æäº¤      ç¼–è¾‘ tasks.jsonï¼Œç„¶å lab-gpu submit-batch --file tasks.json
âœ“ å¯è§†åŒ–ç®¡ç†    lab-gpu tui (æŒ‰ k æ€ä»»åŠ¡, r é‡è¯•, t æå‡ä¼˜å…ˆçº§, q é€€å‡º)
âœ“ å®æ—¶ç›‘æ§      lab-gpu logs <id> -f

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ¯ ä¼˜å…ˆçº§è¯´æ˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

  high    âš¡ ç´§æ€¥ä»»åŠ¡ï¼Œç«‹å³è°ƒåº¦
  normal  ğŸ“‹ æ™®é€šä»»åŠ¡ï¼ŒæŒ‰é¡ºåºæ‰§è¡Œ
  low     ğŸŒ™ ä¸æ€¥ä»»åŠ¡ï¼Œå¤œé—´åŠ é€Ÿ

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“š å¸®åŠ©æ–‡æ¡£
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

  README.md       - å®Œæ•´æ–‡æ¡£
  ä½¿ç”¨æŒ‡å—.md     - ä¸­æ–‡è¯¦ç»†æ•™ç¨‹
  quick_start.md  - è‹±æ–‡å¿«é€Ÿå¼€å§‹
  lab-gpu --help  - å‘½ä»¤è¡Œå¸®åŠ©

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸƒ å¿«é€Ÿç¤ºä¾‹
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

  bash example_workflow.sh    # è¿è¡Œå®Œæ•´ç¤ºä¾‹

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

æç¤ºï¼šæœ€æ¨èçš„ä½¿ç”¨æ–¹å¼æ˜¯ lab-gpu tui å¯è§†åŒ–ç•Œé¢ï¼
