#!/bin/bash
# ç®€åŒ–ç‰ˆï¼šä½¿ç”¨ Lab-GPU è¿è¡Œç¤ºä¾‹ä»»åŠ¡
# é€‚åˆå¿«é€Ÿæµ‹è¯•

# æ¿€æ´»ç¯å¢ƒ
source ~/miniconda3/etc/profile.d/conda.sh
conda activate graphAR
cd /home/cwx/workspace/gpudirector

echo "ğŸš€ å¯åŠ¨ Lab-GPU å¹¶è¿è¡Œç¤ºä¾‹ä»»åŠ¡..."
echo ""

# å¯åŠ¨æœåŠ¡
lab-gpu server start --role master --host 127.0.0.1

# æ·»åŠ  GPU èŠ‚ç‚¹
lab-gpu server add-node --name node-1 --gpus 2 --vram 24

# æäº¤ç¤ºä¾‹ä»»åŠ¡
echo "ğŸ“ æäº¤ä»»åŠ¡..."
lab-gpu submit --mem 2G --priority high "python examples/gpu_alloc.py --mock --gb 2 --sleep 10"
lab-gpu submit --mem 1G --priority normal "python examples/gpu_burst.py --mock --gb 1 --cycles 2"
lab-gpu submit --mem 0.5G --priority normal "echo 'Test Task' && sleep 3"

# æ‰§è¡Œè°ƒåº¦
echo ""
echo "âš™ï¸  æ‰§è¡Œè°ƒåº¦..."
lab-gpu server tick

# æŸ¥çœ‹çŠ¶æ€
echo ""
echo "ğŸ“Š ä»»åŠ¡çŠ¶æ€ï¼š"
lab-gpu status

echo ""
echo "âœ… å®Œæˆï¼è¿è¡Œ 'lab-gpu tui' æŸ¥çœ‹å¯è§†åŒ–ç•Œé¢"
