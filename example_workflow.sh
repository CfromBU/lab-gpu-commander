#!/bin/bash
# Lab-GPU å®Œæ•´å·¥ä½œæµç¤ºä¾‹
# ä½¿ç”¨æ–¹æ³•: bash example_workflow.sh

set -e  # é‡åˆ°é”™è¯¯ç«‹å³é€€å‡º

echo "======================================"
echo "   Lab-GPU å®Œæ•´å·¥ä½œæµæ¼”ç¤º"
echo "======================================"

# æ¿€æ´»ç¯å¢ƒ
source ~/miniconda3/etc/profile.d/conda.sh
conda activate graphAR

echo -e "\nâœ… æ­¥éª¤ 1: å¯åŠ¨ Master æœåŠ¡"
lab-gpu server start --role master --host 127.0.0.1
echo "   æœåŠ¡å·²å¯åŠ¨åœ¨ 127.0.0.1"

echo -e "\nâœ… æ­¥éª¤ 2: æ·»åŠ  GPU èŠ‚ç‚¹"
lab-gpu server add-node --name node-1 --gpus 2 --vram 24 --gpu-type "RTX 3090"
echo "   å·²æ·»åŠ èŠ‚ç‚¹: node-1 (2x RTX 3090, 24GB)"

echo -e "\nâœ… æ­¥éª¤ 3: æŸ¥çœ‹å½“å‰çŠ¶æ€"
lab-gpu status
echo ""

echo -e "\nâœ… æ­¥éª¤ 4: æµ‹è¯•ä»»åŠ¡é…ç½® (dry-run)"
echo "   æ­£åœ¨æ£€æŸ¥ tasks.json ä¸­çš„ä»»åŠ¡..."
lab-gpu submit-batch --file tasks.json --dry-run | python -m json.tool
echo ""

echo -e "\nâœ… æ­¥éª¤ 5: æäº¤å•ä¸ªæµ‹è¯•ä»»åŠ¡"
TASK_ID=$(lab-gpu submit --mem 2G --priority high "python examples/gpu_alloc.py --mock --gb 0.5" | grep -oP 'task \K\d+')
echo "   å·²æäº¤ä»»åŠ¡ ID: $TASK_ID"

echo -e "\nâœ… æ­¥éª¤ 6: æ‰¹é‡æäº¤ tasks.json ä¸­çš„ä»»åŠ¡"
lab-gpu submit-batch --file tasks.json
echo "   æ‰¹é‡ä»»åŠ¡å·²æäº¤"

echo -e "\nâœ… æ­¥éª¤ 7: æ‰§è¡Œè°ƒåº¦"
lab-gpu server tick
echo "   è°ƒåº¦å®Œæˆ"

echo -e "\nâœ… æ­¥éª¤ 8: æŸ¥çœ‹è¯¦ç»†çŠ¶æ€"
lab-gpu status --json | python -m json.tool
echo ""

echo -e "\n======================================"
echo "   æ¼”ç¤ºå®Œæˆï¼"
echo "======================================"
echo ""
echo "ğŸ’¡ æ¥ä¸‹æ¥ä½ å¯ä»¥ï¼š"
echo "   1. æŸ¥çœ‹ä»»åŠ¡æ—¥å¿—: lab-gpu logs <task_id>"
echo "   2. å¯åŠ¨ TUI ç•Œé¢: lab-gpu tui"
echo "   3. æŸ¥çœ‹çŠ¶æ€: lab-gpu status"
echo "   4. æäº¤æ›´å¤šä»»åŠ¡: lab-gpu submit --mem 10G \"your command\""
echo ""
